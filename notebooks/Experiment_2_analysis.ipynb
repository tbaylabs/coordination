{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated trial results saved to /workspaces/coordination/pipeline/4_analysis/trial_results_aggregated.csv\n",
      "Data validation warning: 1 issue(s) found\n",
      "Data preparation: removed 1 rows (unanswered) and 5 rows (balance)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.analysis.aggregate_trial_results import aggregate_trial_results\n",
    "from src.analysis.repeated_measures_anova import (\n",
    "    run_repeated_measures_anova,\n",
    "    print_rm_anova_summary,\n",
    "    prepare_repeated_measures_anova_exp2\n",
    ")\n",
    "\n",
    "# Create summary stats using default results folder path\n",
    "aggregate_trial_results = aggregate_trial_results()\n",
    "\n",
    "# Prepare data for analysis\n",
    "repeated_df_31 = prepare_repeated_measures_anova_exp2(aggregate_trial_results, 'llama_31')\n",
    "\n",
    "# Run the repeated measures ANOVA\n",
    "anova_results_31 = run_repeated_measures_anova(repeated_df_31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Repeated Measures ANOVA Summary ===\n",
      "\n",
      "TOP_PROP:\n",
      "\n",
      "Descriptive Statistics:\n",
      "+---------------------+---------+--------+-------+\n",
      "|                     |   count |   mean |   std |\n",
      "+=====================+=========+========+=======+\n",
      "| ('405B', 'with')    |      20 |  0.623 | 0.189 |\n",
      "+---------------------+---------+--------+-------+\n",
      "| ('405B', 'without') |      20 |  0.582 | 0.165 |\n",
      "+---------------------+---------+--------+-------+\n",
      "| ('70B', 'with')     |      20 |  0.528 | 0.134 |\n",
      "+---------------------+---------+--------+-------+\n",
      "| ('70B', 'without')  |      20 |  0.529 | 0.131 |\n",
      "+---------------------+---------+--------+-------+\n",
      "| ('8B', 'with')      |      20 |  0.36  | 0.052 |\n",
      "+---------------------+---------+--------+-------+\n",
      "| ('8B', 'without')   |      20 |  0.438 | 0.122 |\n",
      "+---------------------+---------+--------+-------+\n",
      "\n",
      "Model Size Effect:\n",
      "F(2,38) = 16.52, p = 6.88e-06, η² = 0.278\n",
      "→ strong evidence was found for a large effect of model size\n",
      "\n",
      "Reasoning Effect:\n",
      "F(1,19) = 0.68, p = 0.421, η² = 0.002\n",
      "→ no evidence was found for an effect of reasoning condition\n",
      "\n",
      "Interaction Effect:\n",
      "F(2,38) = 7.73, p = 0.002, η² = 0.031\n",
      "→ evidence was found for an interaction between model size and reasoning\n",
      "\n",
      "CONVERGENCE:\n",
      "\n",
      "Descriptive Statistics:\n",
      "+---------------------+---------+--------+-------+\n",
      "|                     |   count |   mean |   std |\n",
      "+=====================+=========+========+=======+\n",
      "| ('405B', 'with')    |      20 |  0.492 | 0.191 |\n",
      "+---------------------+---------+--------+-------+\n",
      "| ('405B', 'without') |      20 |  0.452 | 0.155 |\n",
      "+---------------------+---------+--------+-------+\n",
      "| ('70B', 'with')     |      20 |  0.391 | 0.117 |\n",
      "+---------------------+---------+--------+-------+\n",
      "| ('70B', 'without')  |      20 |  0.392 | 0.099 |\n",
      "+---------------------+---------+--------+-------+\n",
      "| ('8B', 'with')      |      20 |  0.258 | 0.026 |\n",
      "+---------------------+---------+--------+-------+\n",
      "| ('8B', 'without')   |      20 |  0.319 | 0.095 |\n",
      "+---------------------+---------+--------+-------+\n",
      "\n",
      "Model Size Effect:\n",
      "F(2,38) = 16.23, p = 8.02e-06, η² = 0.276\n",
      "→ strong evidence was found for a large effect of model size\n",
      "\n",
      "Reasoning Effect:\n",
      "F(1,19) = 0.27, p = 0.608, η² = 0.001\n",
      "→ no evidence was found for an effect of reasoning condition\n",
      "\n",
      "Interaction Effect:\n",
      "F(2,38) = 8.16, p = 0.001, η² = 0.028\n",
      "→ evidence was found for an interaction between model size and reasoning\n",
      "\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "#overview\n",
    "print_rm_anova_summary(anova_results_31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data validation warning: 1 issue(s) found\n",
      "Data preparation: removed 11 rows (unanswered) and 29 rows (balance)\n"
     ]
    }
   ],
   "source": [
    "# # Prepare data for analysis\n",
    "repeated_df_32 = prepare_repeated_measures_anova_exp2(aggregate_trial_results, 'llama_32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Repeated Measures ANOVA Summary ===\n",
      "\n",
      "TOP_PROP:\n",
      "\n",
      "Descriptive Statistics:\n",
      "+-------------------+---------+--------+-------+\n",
      "|                   |   count |   mean |   std |\n",
      "+===================+=========+========+=======+\n",
      "| ('1B', 'with')    |      11 |  0.312 | 0.052 |\n",
      "+-------------------+---------+--------+-------+\n",
      "| ('1B', 'without') |      11 |  0.41  | 0.07  |\n",
      "+-------------------+---------+--------+-------+\n",
      "| ('3B', 'with')    |      11 |  0.398 | 0.072 |\n",
      "+-------------------+---------+--------+-------+\n",
      "| ('3B', 'without') |      11 |  0.415 | 0.085 |\n",
      "+-------------------+---------+--------+-------+\n",
      "\n",
      "Model Size Effect:\n",
      "F(1,10) = 2.84, p = 1.23e-01, η² = 0.104\n",
      "→ no evidence was found for a medium effect of model size\n",
      "\n",
      "Reasoning Effect:\n",
      "F(1,10) = 11.95, p = 0.006, η² = 0.153\n",
      "→ evidence was found for an effect of reasoning condition\n",
      "\n",
      "Interaction Effect:\n",
      "F(1,10) = 5.84, p = 0.036, η² = 0.083\n",
      "→ some evidence was found for an interaction between model size and reasoning\n",
      "\n",
      "CONVERGENCE:\n",
      "\n",
      "Descriptive Statistics:\n",
      "+-------------------+---------+--------+-------+\n",
      "|                   |   count |   mean |   std |\n",
      "+===================+=========+========+=======+\n",
      "| ('1B', 'with')    |      11 |  0.231 | 0.018 |\n",
      "+-------------------+---------+--------+-------+\n",
      "| ('1B', 'without') |      11 |  0.296 | 0.042 |\n",
      "+-------------------+---------+--------+-------+\n",
      "| ('3B', 'with')    |      11 |  0.288 | 0.036 |\n",
      "+-------------------+---------+--------+-------+\n",
      "| ('3B', 'without') |      11 |  0.301 | 0.047 |\n",
      "+-------------------+---------+--------+-------+\n",
      "\n",
      "Model Size Effect:\n",
      "F(1,10) = 4.82, p = 5.28e-02, η² = 0.157\n",
      "→ no evidence was found for a large effect of model size\n",
      "\n",
      "Reasoning Effect:\n",
      "F(1,10) = 18.75, p = 0.001, η² = 0.231\n",
      "→ evidence was found for an effect of reasoning condition\n",
      "\n",
      "Interaction Effect:\n",
      "F(1,10) = 7.23, p = 0.023, η² = 0.118\n",
      "→ some evidence was found for an interaction between model size and reasoning\n",
      "\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "# Run the repeated measures ANOVA\n",
    "anova_results_32 = run_repeated_measures_anova(repeated_df_32)\n",
    "print_rm_anova_summary(anova_results_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying first 20 rows (total: 60):\n",
      "\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| model         | task_options         |   convergence_without_reasoning |   convergence_with_reasoning |   top_prop_without_reasoning |   top_prop_with_reasoning | model_size   |\n",
      "+===============+======================+=================================+==============================+==============================+===========================+==============+\n",
      "| llama-31-405b | colours              |                        0.275694 |                     0.257222 |                     0.391667 |                  0.391667 | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | colours-text         |                        0.38625  |                     0.387639 |                     0.533333 |                  0.55     | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | emoji-1              |                        0.353889 |                     0.302361 |                     0.5      |                  0.391667 | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | emoji-1-text         |                        0.624167 |                     0.708194 |                     0.775    |                  0.833333 | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | emoji-2              |                        0.384028 |                     0.402083 |                     0.508333 |                  0.583333 | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | emoji-2-text         |                        0.69125  |                     0.60625  |                     0.825    |                  0.766667 | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | emoji-3              |                        0.642778 |                     0.594861 |                     0.791667 |                  0.758333 | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | emoji-3-text         |                        0.358333 |                     0.373472 |                     0.483333 |                  0.475    | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | kanji-nature         |                        0.346528 |                     0.32875  |                     0.516667 |                  0.441667 | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | kanji-nature-english |                        0.489306 |                     0.601389 |                     0.6      |                  0.741667 | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | kanji-random         |                        0.266111 |                     0.274306 |                     0.333333 |                  0.391667 | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | kanji-random-english |                        0.38875  |                     0.401806 |                     0.558333 |                  0.583333 | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | letters              |                        0.77125  |                     0.842917 |                     0.875    |                  0.916667 | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | numbers              |                        0.44875  |                     0.730972 |                     0.616667 |                  0.85     | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | numbers-text         |                        0.376111 |                     0.557917 |                     0.466667 |                  0.708333 | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | shapes-1-icon        |                        0.280139 |                     0.301667 |                     0.35     |                  0.4      | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | shapes-1-text        |                        0.671389 |                     0.718472 |                     0.808333 |                  0.841667 | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | shapes-2-icon        |                        0.35875  |                     0.410694 |                     0.45     |                  0.558333 | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | shapes-2-text        |                        0.589167 |                     0.773056 |                     0.741667 |                  0.875    | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n",
      "| llama-31-405b | shapes-3-icon        |                        0.342778 |                     0.273889 |                     0.516667 |                  0.4      | 405B         |\n",
      "+---------------+----------------------+---------------------------------+------------------------------+------------------------------+---------------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "from src.analysis.visualization import (\n",
    "    plot_model_comparison,\n",
    "    create_comprehensive_analysis,\n",
    ")\n",
    "from src.analysis.df_formatting import print_nice_dataframe\n",
    "# create_comprehensive_analysis(repeated_df_31)\n",
    "# plot_model_comparison(repeated_df_31)\n",
    "print_nice_dataframe(repeated_df_31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
